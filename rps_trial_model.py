# -*- coding: utf-8 -*-
"""RPS_trial_model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1h9_jJw_wizxVXzRaRbQkNFqjVH46vOQb
"""

import tensorflow as tf
#tf.test.gpu_device_name()
#from tensorflow.python.client import device_lib
#device_lib.list_local_devices()
#from google.colab import drive
#drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/drive/My Drive/RockPaperScissors

#!ls

# import required packages
import cv2
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Flatten
from keras.optimizers import Adam
from keras.preprocessing.image import ImageDataGenerator

# Initialize image data generator with rescaling
train_data_gen = ImageDataGenerator(rescale=1./255)
validation_data_gen = ImageDataGenerator(rescale=1./255)

# Preprocess all test images
train_generator = train_data_gen.flow_from_directory(
        'data/train',
        target_size=(48, 48),
        batch_size=64,
        color_mode="grayscale",
        class_mode='categorical')

# Preprocess all train images
validation_generator = validation_data_gen.flow_from_directory(
        'data/test',
        target_size=(48, 48),
        batch_size=64,
        color_mode="grayscale",
        class_mode='categorical')

# create model structure
RPS_model = Sequential()

RPS_model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(48, 48, 1)))
RPS_model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))
RPS_model.add(MaxPooling2D(pool_size=(2, 2)))
RPS_model.add(Dropout(0.25))

RPS_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))
RPS_model.add(MaxPooling2D(pool_size=(2, 2)))
RPS_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))
RPS_model.add(MaxPooling2D(pool_size=(2, 2)))
RPS_model.add(Dropout(0.25))

RPS_model.add(Flatten())
RPS_model.add(Dense(1024, activation='relu'))
RPS_model.add(Dropout(0.5))
RPS_model.add(Dense(3, activation='softmax'))

cv2.ocl.setUseOpenCL(False)
#lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(
#    initial_learning_rate=0.1,
#    decay_steps=10000,
#    decay_rate=0.1)
# optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)

# RPS_model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.0001, decay=1e-6), metrics=['accuracy'])
# RPS_model.compile(loss='categorical_crossentropy', optimizer= Adam(learning_rate=lr_schedule), metrics=['accuracy'])
RPS_model.compile(loss='categorical_crossentropy', optimizer= tf.keras.optimizers.Adam(), metrics=['accuracy'])

# Train the neural network/model
# RPS_model_info = RPS_model.fit_generator(
RPS_model_info = RPS_model.fit(
          train_generator,
        steps_per_epoch=7145 // 64,
        epochs=100,
        validation_data=validation_generator,
        validation_steps=206 // 64)

# save model structure in jason file
model_json = RPS_model.to_json()
with open("RPS_model.json", "w") as json_file:
    json_file.write(model_json)

# save trained model weight in .h5 file
RPS_model.save_weights('RPS_model.h5')
